<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI Voice Assistant</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    .chat-container::-webkit-scrollbar {
      width: 8px;
    }
    .chat-container::-webkit-scrollbar-track {
      background: #f1f1f1;
    }
    .chat-container::-webkit-scrollbar-thumb {
      background: #888;
      border-radius: 4px;
    }
    .chat-container::-webkit-scrollbar-thumb:hover {
      background: #555;
    }
  </style>
</head>
<body class="bg-gray-100 min-h-screen flex font-sans">
  <div class="w-64 bg-gray-800 text-white p-4 flex flex-col">
    <h1 class="text-2xl font-bold mb-6">AI Assistant</h1>
    <div class="flex-1 overflow-y-auto space-y-2">
      <div class="p-2 bg-gray-700 rounded cursor-pointer hover:bg-gray-600">New Chat</div>
      <div class="p-2 bg-gray-700 rounded cursor-pointer hover:bg-gray-600">Previous Chat 1</div>
      <div class="p-2 bg-gray-700 rounded cursor-pointer hover:bg-gray-600">Previous Chat 2</div>
    </div>
  </div>
  <div class="flex-1 flex flex-col">
    <div class="flex-1 p-6 overflow-y-auto chat-container bg-white">
      <div id="results" class="space-y-4"></div>
    </div>
    <div class="p-4 bg-white border-t border-gray-200">
      <div class="max-w-3xl mx-auto flex flex-col space-y-2">
        <div class="flex items-center space-x-2">
          <input type="text" id="textInput" placeholder="Type your question..." class="flex-1 p-3 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500">
          <button id="submitBtn" class="bg-blue-600 text-white p-3 rounded-lg hover:bg-blue-700 transition flex items-center justify-center">
            <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 19l9 2-9-18-9 18 9-2zm0 0v-8"></path></svg>
          </button>
          <button id="voiceBtn" class="bg-blue-600 text-white p-3 rounded-lg hover:bg-blue-700 transition flex items-center justify-center">
            <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path></svg>
          </button>
          <button id="stopSpeakBtn" class="bg-gray-500 text-white p-3 rounded-lg hover:bg-gray-600 transition flex items-center justify-center" disabled>
            <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/>
            </svg>
          </button>          
        </div>
        <div class="flex items-center space-x-2">
          <input type="file" id="imageUpload" accept="image/jpeg,image/png" class="flex-1 p-2 border border-gray-300 rounded-lg file:mr-4 file:py-2 file:px-4 file:rounded-md file:border-0 file:bg-blue-500 file:text-white file:hover:bg-blue-600">
          <div id="imagePreview" class="hidden max-w-xs">
            <canvas id="imageCanvas" class="border border-gray-200 rounded-lg max-w-full"></canvas>
          </div>
        </div>
      </div>
    </div>
  </div>

  <script>
    const textInput = document.getElementById('textInput');
    const submitBtn = document.getElementById('submitBtn');
    const imageUpload = document.getElementById('imageUpload');
    const voiceBtn = document.getElementById('voiceBtn');
    const canvas = document.getElementById('imageCanvas');
    const ctx = canvas.getContext('2d');
    const resultsDiv = document.getElementById('results');
    const imagePreview = document.getElementById('imagePreview');
    const stopSpeakBtn = document.getElementById('stopSpeakBtn');


    textInput.addEventListener('keypress', (e) => {
      if (e.key === 'Enter' && textInput.value.trim()) {
        processTextInput(textInput.value.trim());
        textInput.value = '';
      }
    });

    submitBtn.addEventListener('click', () => {
      if (textInput.value.trim()) {
        processTextInput(textInput.value.trim());
        textInput.value = '';
      }
    });

    async function processTextInput(text) {
      displayResult('You', text, '', 'user');
      try {
        const response = await fetch('https://c7fd791c63b0.ngrok-free.app/api/text', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ prompt: text })
        });
        if (!response.ok) {
          throw new Error(`Server responded with status ${response.status}`);
        }

        let responseText = '';
        const reader = response.body.getReader();
        const decoder = new TextDecoder();

        const assistantContainer = document.createElement('div');
        assistantContainer.className = 'bg-gray-200 text-gray-800 mr-auto p-3 rounded-lg max-w-md';
        assistantContainer.innerHTML = `<span class="font-semibold">Assistant:</span> <span id="assistantText"></span>`;
        resultsDiv.appendChild(assistantContainer);
        resultsDiv.scrollTop = resultsDiv.scrollHeight;

        const assistantTextSpan = assistantContainer.querySelector('#assistantText');

        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          const chunk = decoder.decode(value);
          responseText += chunk;
          assistantTextSpan.textContent = responseText;
          resultsDiv.scrollTop = resultsDiv.scrollHeight;
        }

        speak(responseText);
      } catch (error) {
        displayResult('Assistant', text, 'Error: Failed to connect to the server. Is it running?', 'error');
      }
    }

    imageUpload.addEventListener('change', async (event) => {
      const file = event.target.files[0];
      if (file) {
        const reader = new FileReader();
        reader.onload = async (e) => {
          const img = new Image();
          img.onload = async () => {
            canvas.width = img.width;
            canvas.height = img.height;
            ctx.drawImage(img, 0, 0);
            imagePreview.classList.remove('hidden');
            canvas.toBlob(async (blob) => {
              try {
                const formData = new FormData();
                formData.append("file", blob);
                formData.append("upload_preset", "haiku_unsigned"); // change if needed

                const cloudName = "dirgxbmfu"; // replace with your actual Cloudinary name

                const uploadRes = await fetch(`https://api.cloudinary.com/v1_1/${cloudName}/image/upload`, {
                    method: "POST",
                    body: formData
                });

                const uploadData = await uploadRes.json();
                const imageUrl = uploadData.secure_url;

                displayResult('You', `Uploaded image: ${file.name}`, '', 'image', imageUrl);

                // Send to Claude-compatible backend
                const response = await fetch('https://c7fd791c63b0.ngrok-free.app/api/image', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        imageUrl, // 👈 send the public URL
                        prompt: 'Analyze this image for potential issues (e.g., leaks) and provide recommendations.'
                    })
                });

                let responseText = '';
                const reader = response.body.getReader();
                const decoder = new TextDecoder();

                const assistantContainer = document.createElement('div');
                assistantContainer.className = 'bg-gray-200 text-gray-800 mr-auto p-3 rounded-lg max-w-md';
                assistantContainer.innerHTML = `<span class="font-semibold">Assistant:</span> <span id="assistantImageText"></span>`;
                resultsDiv.appendChild(assistantContainer);
                resultsDiv.scrollTop = resultsDiv.scrollHeight;

                const assistantTextSpan = assistantContainer.querySelector('#assistantImageText');

                while (true) {
                    const { done, value } = await reader.read();
                    if (done) break;
                    const chunk = decoder.decode(value);
                    responseText += chunk;
                    assistantTextSpan.textContent = responseText;
                    resultsDiv.scrollTop = resultsDiv.scrollHeight;
                }

                speak(responseText);
            }   catch (error) {
                displayResult('Assistant', `Uploaded image: ${file.name}`, 'Error: Failed to connect to the server. Is it running?', 'error');
            }
          }, 'image/jpeg');
          };
          img.src = e.target.result;
        };
        reader.readAsDataURL(file);
      }
    });

    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = 'en-US';
    let isRecording = false;

    voiceBtn.addEventListener('click', () => {
      if (!isRecording) {
        recognition.start();
        voiceBtn.innerHTML = `<svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path></svg>`;
        voiceBtn.classList.replace('bg-blue-600', 'bg-red-600');
        voiceBtn.classList.replace('hover:bg-blue-700', 'hover:bg-red-700');
        isRecording = true;
      } else {
        recognition.stop();
        voiceBtn.innerHTML = `<svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path></svg>`;
        voiceBtn.classList.replace('bg-red-600', 'bg-blue-600');
        voiceBtn.classList.replace('hover:bg-red-700', 'hover:bg-blue-700');
        isRecording = false;
      }
    });

    stopSpeakBtn.addEventListener('click', () => {
        speechSynthesis.cancel();         // ⛔ 停止语音朗读
        stopSpeakBtn.disabled = true;     // 禁用按钮
    });


    recognition.onresult = (event) => {
      const transcript = event.results[0][0].transcript;
      processTextInput(transcript);
    };

    recognition.onerror = (event) => {
      displayResult('You', 'Speech recognition failed', 'Sorry, there was an error with voice input. Try again.', 'error');
      speak('Sorry, there was an error with voice input. Try again.');
    };

    recognition.onend = () => {
      if (isRecording) recognition.start();
    };

    function displayResult(sender, input, response, type, imageData = '') {
      const userBubble = type === 'user' || type === 'image' ? 'bg-blue-100 text-gray-800 ml-auto' : 'bg-red-100 text-gray-800 ml-auto';
      const assistantBubble = 'bg-gray-200 text-gray-800 mr-auto';
      const resultHTML = `
        <div class="flex flex-col space-y-2">
          <div class="${type === 'assistant' ? assistantBubble : userBubble} p-3 rounded-lg max-w-md ${type === 'image' ? 'flex flex-col' : ''}">
            <span class="font-semibold">${sender}:</span> ${input}
            ${type === 'image' ? `<img src="${imageData}" class="mt-2 max-w-xs rounded" />` : ''}
          </div>
          ${response ? `
          <div class="${assistantBubble} p-3 rounded-lg max-w-md">
            <span class="font-semibold">Assistant:</span> ${response}
          </div>` : ''}
        </div>
      `;
      resultsDiv.innerHTML += resultHTML;
      resultsDiv.scrollTop = resultsDiv.scrollHeight;
    }

    function speak(text) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'en-US';
      stopSpeakBtn.disabled = false;

      utterance.onend = () => {
        stopSpeakBtn.disabled = true; 
      };
      window.speechSynthesis.speak(utterance);
    }
  </script>
</body>
</html>
